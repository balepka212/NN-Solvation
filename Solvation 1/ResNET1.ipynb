{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DESCRIPTION\n",
    "\n",
    "As solvent input - its nD, alpha, beta, gamma, epsilon, phi, psi\n",
    "As solute input - its classes - levels 1, 2, 3\n",
    "Linear network:\n",
    "    Linear(10, 512)\n",
    "    ReLU\n",
    "    Linear(512, 128)\n",
    "    ReLU\n",
    "    Linear(128, 10)\n",
    "    ReLU\n",
    "    Linear(10, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deleting charges species"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "filename = r'/Users/balepka/Yandex.Disk.localized/Study/Lab/Neural Network/MNSol-v2009_energies_v2.tsv'\n",
    "with open(filename) as f:\n",
    "    t=0\n",
    "    data = pd.read_table(f)\n",
    "    df1 = pd.DataFrame(data)\n",
    "\n",
    "df2 = df1.loc[df1['Charge'].isin([0])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   No. FileHandle SoluteName  Charge  Level1  Level2  Level3     Solvent  \\\n0    1    0400hyd   hydrogen       0       1       1       0       water   \n1    2    0400hyd   hydrogen       0       1       1       0  hexadecane   \n2    3    0400hyd   hydrogen       0       1       1       0     octanol   \n3    4    0216amm    ammonia       0       1       2       0       water   \n4    5    0216amm    ammonia       0       1       2       0  hexadecane   \n5    6    0216amm    ammonia       0       1       2       0     benzene   \n\n   DeltaGsolv type  ...    S   HS   SS    P   OP   SP   Si  OSi   OS  \\\n0        2.33  abs  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n1        1.64  abs  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n2        1.76  abs  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n3       -4.29  abs  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n4       -0.93  abs  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n5       -1.12  abs  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n\n   TotalArea  \n0     39.747  \n1     39.747  \n2     39.747  \n3     62.789  \n4     62.789  \n5     62.789  \n\n[6 rows x 49 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>No.</th>\n      <th>FileHandle</th>\n      <th>SoluteName</th>\n      <th>Charge</th>\n      <th>Level1</th>\n      <th>Level2</th>\n      <th>Level3</th>\n      <th>Solvent</th>\n      <th>DeltaGsolv</th>\n      <th>type</th>\n      <th>...</th>\n      <th>S</th>\n      <th>HS</th>\n      <th>SS</th>\n      <th>P</th>\n      <th>OP</th>\n      <th>SP</th>\n      <th>Si</th>\n      <th>OSi</th>\n      <th>OS</th>\n      <th>TotalArea</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0400hyd</td>\n      <td>hydrogen</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>water</td>\n      <td>2.33</td>\n      <td>abs</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>39.747</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0400hyd</td>\n      <td>hydrogen</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>hexadecane</td>\n      <td>1.64</td>\n      <td>abs</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>39.747</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0400hyd</td>\n      <td>hydrogen</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>octanol</td>\n      <td>1.76</td>\n      <td>abs</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>39.747</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0216amm</td>\n      <td>ammonia</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>water</td>\n      <td>-4.29</td>\n      <td>abs</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>62.789</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0216amm</td>\n      <td>ammonia</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>hexadecane</td>\n      <td>-0.93</td>\n      <td>abs</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>62.789</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0216amm</td>\n      <td>ammonia</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>benzene</td>\n      <td>-1.12</td>\n      <td>abs</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>62.789</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows Ã— 49 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "water                  345\noctanol                206\nhexadecane             190\nchloroform             105\ncyclohexane             91\n                      ... \nbutanol-water            1\ndibutylether-water       1\nchlorobenzene-water      1\ndibromoethane-water      1\nnitrobenzene-water       1\nName: Solvent, Length: 106, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Solvent'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "ethanol                                                                                      65\ntoluene                                                                                      60\n2-butanone                                                                                   60\nn-octane                                                                                     53\nnitromethane                                                                                 52\n                                                                                             ..\nbutenyne                                                                                      1\nfluoroacetamide                                                                               1\nbenzylalcohol                                                                                 1\nazetidine                                                                                     1\n(2-dimethylamino-5,6-dimethyl-pyrimidin-4-yl) N,N-dimethylcarbamate (pirimor, pirimicarb)     1\nName: SoluteName, Length: 494, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['SoluteName'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deleting solvent mixtures"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "filename2 = r'/Users/balepka/Yandex.Disk.localized/Study/Lab/Neural Network/MNSolDatabase_v2012/Solvent_properties.tsv'\n",
    "with open(filename2) as f:\n",
    "    data = pd.read_table(f, header=1)\n",
    "    solvent_props = pd.DataFrame(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "octanol-water\n",
      "diethylether-water\n",
      "chloroform-water\n",
      "heptane-water\n",
      "isopropyltoluene\n",
      "cyclohexane-water\n",
      "benzene-water\n",
      "ethylacetate-water\n",
      "dichloroethane-water\n",
      "carbontet-water\n",
      "hexane-water\n",
      "butanol-water\n",
      "dibutylether-water\n",
      "chlorobenzene-water\n",
      "dibromoethane-water\n",
      "nitrobenzene-water\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "for name, count in df2['Solvent'].value_counts().items():\n",
    "    row = solvent_props.loc[solvent_props['Name'] == name]\n",
    "    values = np.array(row[['nD', 'alpha', 'beta', 'gamma', 'epsilon', 'phi', 'psi']])\n",
    "    # print(f'{name} -> {count} -> {values.shape[0]}')\n",
    "    if values.shape[0] == 0:\n",
    "        print(name)\n",
    "        names.append(name)\n",
    "df3 = df2.loc[~df2['Solvent'].isin(names)]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CREATING X and y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X1 = torch.from_numpy(df3.iloc[:, 4:7].values).float()\n",
    "X2 = df3['Solvent'].values\n",
    "X3 = pd.DataFrame()\n",
    "for s in X2:\n",
    "    # print(s)\n",
    "    # print(solvent_props.loc[solvent_props['Name'] == s])\n",
    "    X3 = X3.append(solvent_props.loc[solvent_props['Name'] == s])\n",
    "X4 = torch.from_numpy(X3.iloc[:, 2:9].values).float()\n",
    "X = torch.hstack((X1, X4))\n",
    "y = torch.from_numpy(df3['DeltaGsolv'].values).float()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2411, 10])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define 1D ResNet network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "resnet for 1-d signal data, pytorch version\n",
    "\n",
    "Shenda Hong, Oct 2019\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (torch.tensor(self.data[index], dtype=torch.float), torch.tensor(self.label[index], dtype=torch.long))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class MyConv1dPadSame(nn.Module):\n",
    "    \"\"\"\n",
    "    extend nn.Conv1d to support SAME padding\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups=1):\n",
    "        super(MyConv1dPadSame, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.conv = torch.nn.Conv1d(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            groups=self.groups)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        net = x\n",
    "\n",
    "        # compute pad shape\n",
    "        in_dim = net.shape[-1]\n",
    "        out_dim = (in_dim + self.stride - 1) // self.stride\n",
    "        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
    "        pad_left = p // 2\n",
    "        pad_right = p - pad_left\n",
    "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
    "\n",
    "        net = self.conv(net)\n",
    "\n",
    "        return net\n",
    "\n",
    "class MyMaxPool1dPadSame(nn.Module):\n",
    "    \"\"\"\n",
    "    extend nn.MaxPool1d to support SAME padding\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(MyMaxPool1dPadSame, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = 1\n",
    "        self.max_pool = torch.nn.MaxPool1d(kernel_size=self.kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        net = x\n",
    "\n",
    "        # compute pad shape\n",
    "        in_dim = net.shape[-1]\n",
    "        out_dim = (in_dim + self.stride - 1) // self.stride\n",
    "        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
    "        pad_left = p // 2\n",
    "        pad_right = p - pad_left\n",
    "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
    "\n",
    "        net = self.max_pool(net)\n",
    "\n",
    "        return net\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet Basic Block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups, downsample, use_bn, use_do, is_first_block=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.downsample = downsample\n",
    "        if self.downsample:\n",
    "            self.stride = stride\n",
    "        else:\n",
    "            self.stride = 1\n",
    "        self.is_first_block = is_first_block\n",
    "        self.use_bn = use_bn\n",
    "        self.use_do = use_do\n",
    "\n",
    "        # the first conv\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.do1 = nn.Dropout(p=0.5)\n",
    "        self.conv1 = MyConv1dPadSame(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=self.stride,\n",
    "            groups=self.groups)\n",
    "\n",
    "        # the second conv\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.do2 = nn.Dropout(p=0.5)\n",
    "        self.conv2 = MyConv1dPadSame(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            groups=self.groups)\n",
    "\n",
    "        self.max_pool = MyMaxPool1dPadSame(kernel_size=self.stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = x\n",
    "\n",
    "        # the first conv\n",
    "        out = x\n",
    "        if not self.is_first_block:\n",
    "            if self.use_bn:\n",
    "                out = self.bn1(out)\n",
    "            out = self.relu1(out)\n",
    "            if self.use_do:\n",
    "                out = self.do1(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        # the second conv\n",
    "        if self.use_bn:\n",
    "            out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        if self.use_do:\n",
    "            out = self.do2(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        # if downsample, also downsample identity\n",
    "        if self.downsample:\n",
    "            identity = self.max_pool(identity)\n",
    "\n",
    "        # if expand channel, also pad zeros to identity\n",
    "        if self.out_channels != self.in_channels:\n",
    "            identity = identity.transpose(-1,-2)\n",
    "            ch1 = (self.out_channels-self.in_channels)//2\n",
    "            ch2 = self.out_channels-self.in_channels-ch1\n",
    "            identity = F.pad(identity, (ch1, ch2), \"constant\", 0)\n",
    "            identity = identity.transpose(-1,-2)\n",
    "\n",
    "        # shortcut\n",
    "        out += identity\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet1D(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    Input:\n",
    "        X: (n_samples, n_channel, n_length)\n",
    "        Y: (n_samples)\n",
    "\n",
    "    Output:\n",
    "        out: (n_samples)\n",
    "\n",
    "    Pararmetes:\n",
    "        in_channels: dim of input, the same as n_channel\n",
    "        base_filters: number of filters in the first several Conv layer, it will double at every 4 layers\n",
    "        kernel_size: width of kernel\n",
    "        stride: stride of kernel moving\n",
    "        groups: set larget to 1 as ResNeXt\n",
    "        n_block: number of blocks\n",
    "        n_classes: number of classes\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, base_filters, kernel_size, stride, groups, n_block, n_classes, downsample_gap=2, increasefilter_gap=4, use_bn=True, use_do=True, verbose=False):\n",
    "        super(ResNet1D, self).__init__()\n",
    "\n",
    "        self.verbose = verbose\n",
    "        self.n_block = n_block\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.use_bn = use_bn\n",
    "        self.use_do = use_do\n",
    "\n",
    "        self.downsample_gap = downsample_gap # 2 for base model\n",
    "        self.increasefilter_gap = increasefilter_gap # 4 for base model\n",
    "\n",
    "        # first block\n",
    "        self.first_block_conv = MyConv1dPadSame(in_channels=in_channels, out_channels=base_filters, kernel_size=self.kernel_size, stride=1)\n",
    "        self.first_block_bn = nn.BatchNorm1d(base_filters)\n",
    "        self.first_block_relu = nn.ReLU()\n",
    "        out_channels = base_filters\n",
    "\n",
    "        # residual blocks\n",
    "        self.basicblock_list = nn.ModuleList()\n",
    "        for i_block in range(self.n_block):\n",
    "            # is_first_block\n",
    "            if i_block == 0:\n",
    "                is_first_block = True\n",
    "            else:\n",
    "                is_first_block = False\n",
    "            # downsample at every self.downsample_gap blocks\n",
    "            if i_block % self.downsample_gap == 1:\n",
    "                downsample = True\n",
    "            else:\n",
    "                downsample = False\n",
    "            # in_channels and out_channels\n",
    "            if is_first_block:\n",
    "                in_channels = base_filters\n",
    "                out_channels = in_channels\n",
    "            else:\n",
    "                # increase filters at every self.increasefilter_gap blocks\n",
    "                in_channels = int(base_filters*2**((i_block-1)//self.increasefilter_gap))\n",
    "                if (i_block % self.increasefilter_gap == 0) and (i_block != 0):\n",
    "                    out_channels = in_channels * 2\n",
    "                else:\n",
    "                    out_channels = in_channels\n",
    "\n",
    "            tmp_block = BasicBlock(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=self.kernel_size,\n",
    "                stride = self.stride,\n",
    "                groups = self.groups,\n",
    "                downsample=downsample,\n",
    "                use_bn = self.use_bn,\n",
    "                use_do = self.use_do,\n",
    "                is_first_block=is_first_block)\n",
    "            self.basicblock_list.append(tmp_block)\n",
    "\n",
    "        # final prediction\n",
    "        self.final_bn = nn.BatchNorm1d(out_channels)\n",
    "        self.final_relu = nn.ReLU(inplace=True)\n",
    "        # self.do = nn.Dropout(p=0.5)\n",
    "        self.dense = nn.Linear(out_channels, n_classes)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = x\n",
    "\n",
    "        # first conv\n",
    "        if self.verbose:\n",
    "            print('input shape', out.shape)\n",
    "        out = self.first_block_conv(out)\n",
    "        if self.verbose:\n",
    "            print('after first conv', out.shape)\n",
    "        if self.use_bn:\n",
    "            out = self.first_block_bn(out)\n",
    "        out = self.first_block_relu(out)\n",
    "\n",
    "        # residual blocks, every block has two conv\n",
    "        for i_block in range(self.n_block):\n",
    "            net = self.basicblock_list[i_block]\n",
    "            if self.verbose:\n",
    "                print('i_block: {0}, in_channels: {1}, out_channels: {2}, downsample: {3}'.format(i_block, net.in_channels, net.out_channels, net.downsample))\n",
    "            out = net(out)\n",
    "            if self.verbose:\n",
    "                print(out.shape)\n",
    "\n",
    "        # final prediction\n",
    "        if self.use_bn:\n",
    "            out = self.final_bn(out)\n",
    "        out = self.final_relu(out)\n",
    "        out = out.mean(-1)\n",
    "        if self.verbose:\n",
    "            print('final pooling', out.shape)\n",
    "        # out = self.do(out)\n",
    "        out = self.dense(out)\n",
    "        if self.verbose:\n",
    "            print('dense', out.shape)\n",
    "        # out = self.softmax(out)\n",
    "        if self.verbose:\n",
    "            print('softmax', out.shape)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class FCNet(nn.Module):\n",
    "    def __init__(self, x_len = 10):\n",
    "        self.x_len = x_len\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(self.x_len, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        self.fc4 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):  # Forward will be Called from  parent __call__ method\n",
    "        x = x.view(-1, self.x_len)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "ids = np.random.permutation(X.shape[0])\n",
    "val_start = int(X.shape[0] * 0.8)\n",
    "test_start = int(X.shape[0] * 0.9)\n",
    "\n",
    "train_ids = ids[:val_start]\n",
    "val_ids = ids[val_start:test_start]\n",
    "test_ids = ids[test_start:]\n",
    "\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = X[train_ids], X[val_ids], X[test_ids], y[train_ids], y[val_ids], y[test_ids]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "X_train = (X_train - mean) / std\n",
    "X_val = (X_val - mean) / std\n",
    "X_test = (X_test - mean) / std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([241, 1, 10])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1 = torch.reshape(X_train, (1928, 1, 10))\n",
    "\n",
    "X_val1 = torch.reshape(X_val, (241, 1, 10))\n",
    "\n",
    "X_val1.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet1D(\n",
      "  (first_block_conv): MyConv1dPadSame(\n",
      "    (conv): Conv1d(1, 2, kernel_size=(3,), stride=(1,))\n",
      "  )\n",
      "  (first_block_bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (first_block_relu): ReLU()\n",
      "  (basicblock_list): ModuleList(\n",
      "    (0): BasicBlock(\n",
      "      (bn1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (do1): Dropout(p=0.5, inplace=False)\n",
      "      (conv1): MyConv1dPadSame(\n",
      "        (conv): Conv1d(2, 2, kernel_size=(3,), stride=(1,))\n",
      "      )\n",
      "      (bn2): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (do2): Dropout(p=0.5, inplace=False)\n",
      "      (conv2): MyConv1dPadSame(\n",
      "        (conv): Conv1d(2, 2, kernel_size=(3,), stride=(1,))\n",
      "      )\n",
      "      (max_pool): MyMaxPool1dPadSame(\n",
      "        (max_pool): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (bn1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (do1): Dropout(p=0.5, inplace=False)\n",
      "      (conv1): MyConv1dPadSame(\n",
      "        (conv): Conv1d(2, 2, kernel_size=(3,), stride=(1,))\n",
      "      )\n",
      "      (bn2): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (do2): Dropout(p=0.5, inplace=False)\n",
      "      (conv2): MyConv1dPadSame(\n",
      "        (conv): Conv1d(2, 2, kernel_size=(3,), stride=(1,))\n",
      "      )\n",
      "      (max_pool): MyMaxPool1dPadSame(\n",
      "        (max_pool): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (bn1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (do1): Dropout(p=0.5, inplace=False)\n",
      "      (conv1): MyConv1dPadSame(\n",
      "        (conv): Conv1d(2, 2, kernel_size=(3,), stride=(1,))\n",
      "      )\n",
      "      (bn2): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (do2): Dropout(p=0.5, inplace=False)\n",
      "      (conv2): MyConv1dPadSame(\n",
      "        (conv): Conv1d(2, 2, kernel_size=(3,), stride=(1,))\n",
      "      )\n",
      "      (max_pool): MyMaxPool1dPadSame(\n",
      "        (max_pool): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (final_relu): ReLU(inplace=True)\n",
      "  (dense): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNet1D(1, 2, 3, 1, 1, 3, 1).to(device)\n",
    "print(model)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCNet(\n",
      "  (fc1): Linear(in_features=10, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (fc4): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = FCNet().to(device)\n",
    "print(model)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Tensor"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1928, 1, 10])\n",
      "tensor([[0.4980],\n",
      "        [0.5259],\n",
      "        [0.2395],\n",
      "        ...,\n",
      "        [0.3214],\n",
      "        [0.3656],\n",
      "        [0.5533]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3-dimensional input for 3-dimensional weight [2, 1, 3], but got 2-dimensional input of size [241, 12] instead",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/16/nd0f005x4vvdmqt98d96xfv00000gn/T/ipykernel_14939/128616035.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m         \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_val\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_pred\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_val\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m         \u001B[0mval_loss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/msuAI/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/16/nd0f005x4vvdmqt98d96xfv00000gn/T/ipykernel_14939/1414439734.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    264\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    265\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'input shape'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 266\u001B[0;31m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfirst_block_conv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    267\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    268\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'after first conv'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/msuAI/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/16/nd0f005x4vvdmqt98d96xfv00000gn/T/ipykernel_14939/1414439734.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     58\u001B[0m         \u001B[0mnet\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mpad_left\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpad_right\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"constant\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 60\u001B[0;31m         \u001B[0mnet\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     61\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mnet\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/msuAI/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/msuAI/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    299\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    300\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 301\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    303\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/msuAI/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    295\u001B[0m                             \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    296\u001B[0m                             _single(0), self.dilation, self.groups)\n\u001B[0;32m--> 297\u001B[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001B[0m\u001B[1;32m    298\u001B[0m                         self.padding, self.dilation, self.groups)\n\u001B[1;32m    299\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected 3-dimensional input for 3-dimensional weight [2, 1, 3], but got 2-dimensional input of size [241, 12] instead"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "for epoch in tqdm(range(1)):\n",
    "    optimizer.zero_grad()\n",
    "    print(X_train1.shape)\n",
    "    y_pred = model(X_train1.to(device))\n",
    "    print(y_pred)\n",
    "    loss = criterion(y_pred.squeeze(), y_train.to(device))\n",
    "    loss.backward()\n",
    "    train_loss.append(loss.item())\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_val.to(device))\n",
    "        loss = criterion(y_pred.squeeze(), y_val.to(device))\n",
    "        val_loss.append(loss.item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss, label=\"train\")\n",
    "plt.plot(val_loss, label=\"val\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3504)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  y_pred = model(X_test.to(device))\n",
    "  test_loss = criterion(y_pred.squeeze(), y_test.to(device))\n",
    "  print(test_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Review the results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "df4 = df3.reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "row = {'index': test_ids,\n",
    "       'Solvent': df4.iloc[test_ids]['Solvent'].values,\n",
    "       'Solute': df4.iloc[test_ids]['SoluteName'].values,\n",
    "       'dG': y_test,\n",
    "       'pred dG': y_pred[:, 0],\n",
    "       'delta': abs(y_test - y_pred[:, 0])}\n",
    "# print(row)\n",
    "test_results = pd.DataFrame.from_dict(row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "for solvent in df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}